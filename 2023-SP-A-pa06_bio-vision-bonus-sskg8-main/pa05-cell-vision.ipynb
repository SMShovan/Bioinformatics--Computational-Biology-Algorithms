{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras import backend as K\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Conv2DTranspose, concatenate\nfrom tensorflow.keras.models import Model\nfrom keras import metrics\nimport keras\nimport os\nimport random\nfrom tqdm import tqdm \nfrom zipfile import ZipFile\nfrom skimage.io import imread, imshow\nfrom skimage.transform import resize\nimport matplotlib.pyplot as plt\nimport pandas as pd","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-05-10T23:21:57.394854Z","iopub.execute_input":"2023-05-10T23:21:57.395212Z","iopub.status.idle":"2023-05-10T23:21:57.401385Z","shell.execute_reply.started":"2023-05-10T23:21:57.395183Z","shell.execute_reply":"2023-05-10T23:21:57.400490Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\n\nclass UNet(tf.keras.Model):\n    def __init__(self, input_shape_, activation_=\"relu\"):\n        super(UNet, self).__init__()\n        self.activation = activation_\n        self.input_shape_ = input_shape_\n        \n        self.kernel_initializer = 'he_uniform'\n        \n        self.conv1a = tf.keras.layers.Conv2D(16, (3, 3), activation=self.activation, kernel_initializer=self.kernel_initializer, padding='same')\n        self.conv1b = tf.keras.layers.Conv2D(16, (3, 3), activation=self.activation, kernel_initializer=self.kernel_initializer, padding='same')\n        self.pool1 = tf.keras.layers.MaxPooling2D((2, 2))\n\n        self.conv2a = tf.keras.layers.Conv2D(32, (3, 3), activation=self.activation, kernel_initializer=self.kernel_initializer, padding='same')\n        self.conv2b = tf.keras.layers.Conv2D(32, (3, 3), activation=self.activation, kernel_initializer=self.kernel_initializer, padding='same')\n        self.pool2 = tf.keras.layers.MaxPooling2D((2, 2))\n\n        self.conv3a = tf.keras.layers.Conv2D(64, (3, 3), activation=self.activation, kernel_initializer=self.kernel_initializer, padding='same')\n        self.conv3b = tf.keras.layers.Conv2D(64, (3, 3), activation=self.activation, kernel_initializer=self.kernel_initializer, padding='same')\n        self.pool3 = tf.keras.layers.MaxPooling2D((2, 2))\n\n        self.conv4a = tf.keras.layers.Conv2D(128, (3, 3), activation=self.activation, kernel_initializer=self.kernel_initializer, padding='same')\n        self.conv4b = tf.keras.layers.Conv2D(128, (3, 3), activation=self.activation, kernel_initializer=self.kernel_initializer, padding='same')\n        self.pool4 = tf.keras.layers.MaxPooling2D((2, 2))\n\n        self.conv5a = tf.keras.layers.Conv2D(256, (3, 3), activation=self.activation, kernel_initializer=self.kernel_initializer, padding='same')\n        self.conv5b = tf.keras.layers.Conv2D(256, (3, 3), activation=self.activation, kernel_initializer=self.kernel_initializer, padding='same')\n\n        self.up6 = tf.keras.layers.Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')\n        self.concat6 = tf.keras.layers.Concatenate()\n        self.conv6a = tf.keras.layers.Conv2D(128, (3, 3), activation=self.activation, kernel_initializer=self.kernel_initializer, padding='same')\n        self.conv6b = tf.keras.layers.Conv2D(128, (3, 3), activation=self.activation, kernel_initializer=self.kernel_initializer, padding='same')\n\n        self.up7 = tf.keras.layers.Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')\n        self.concat7 = tf.keras.layers.Concatenate()\n        self.conv7a = tf.keras.layers.Conv2D(64, (3, 3), activation=self.activation, kernel_initializer=self.kernel_initializer, padding='same')\n        self.conv7b = tf.keras.layers.Conv2D(64, (3, 3), activation=self.activation, kernel_initializer=self.kernel_initializer, padding='same')\n\n        self.up8 = tf.keras.layers.Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')\n        self.up8 = tf.keras.layers.Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')\n        self.concat8 = tf.keras.layers.Concatenate()\n        self.conv8a = tf.keras.layers.Conv2D(32, (3, 3), activation=self.activation, kernel_initializer=self.kernel_initializer, padding='same')\n        self.conv8b = tf.keras.layers.Conv2D(32, (3, 3), activation=self.activation, kernel_initializer=self.kernel_initializer, padding='same')\n\n        self.up9 = tf.keras.layers.Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same')\n        self.concat9 = tf.keras.layers.Concatenate()\n        self.conv9a = tf.keras.layers.Conv2D(16, (3, 3), activation=self.activation, kernel_initializer=self.kernel_initializer, padding='same')\n        self.conv9b = tf.keras.layers.Conv2D(16, (3, 3), activation=self.activation, kernel_initializer=self.kernel_initializer, padding='same')\n\n        self.output_layer = tf.keras.layers.Conv2D(1, (1, 1), activation='sigmoid')\n\n    def call(self, inputs):\n        # Block - 1\n        s = inputs\n\n        # Contraction path\n        c1 = self.conv1a(s)\n        c1 = self.conv1b(c1)\n        p1 = self.pool1(c1)\n\n        c2 = self.conv2a(p1)\n        c2 = self.conv2b(c2)\n        p2 = self.pool2(c2)\n\n        c3 = self.conv3a(p2)\n        c3 = self.conv3b(c3)\n        p3 = self.pool3(c3)\n\n        c4 = self.conv4a(p3)\n        c4 = self.conv4b(c4)\n        p4 = self.pool4(c4)\n\n        c5 = self.conv5a(p4)\n        c5 = self.conv5b(c5)\n\n        # Expansive path\n        u6 = self.up6(c5)\n        u6 = self.concat6([u6, c4])\n        c6 = self.conv6a(u6)\n        c6 = self.conv6b(c6)\n\n        u7 = self.up7(c6)\n        u7 = self.concat7([u7, c3])\n        c7 = self.conv7a(u7)\n        c7 = self.conv7b(c7)\n\n        u8 = self.up8(c7)\n        u8 = self.concat8([u8, c2])\n        c8 = self.conv8a(u8)\n        c8 = self.conv8b(c8)\n\n        u9 = self.up9(c8)\n        u9 = self.concat9([u9, c1])\n        c9 = self.conv9a(u9)\n        c9 = self.conv9b(c9)\n\n        outputs = self.output_layer(c9)\n\n        return outputs\n\n    def dice_coef(self, y_true, y_pred, smooth=100):\n        y_true = tf.cast(y_true, tf.float32)\n        y_pred = tf.cast(y_pred, tf.float32)\n\n        y_true_f = tf.keras.layers.Flatten()(y_true)\n        y_pred_f = tf.keras.layers.Flatten()(y_pred)\n        intersection = tf.reduce_sum(y_true_f * y_pred_f)\n        dice = (2. * intersection + smooth) / (tf.reduce_sum(y_true_f) + tf.reduce_sum(y_pred_f) + smooth)\n        return dice\n    \n    def buildModel(self):\n        inputs = tf.keras.Input(shape=self.input_shape_)\n        outputs = self.call(inputs)\n        model = tf.keras.Model(inputs=inputs, outputs=outputs)\n        return model\n\n    def dice_coef(self, y_true, y_pred, smooth=100):\n        y_true = tf.cast(y_true, tf.float32)\n        y_pred = tf.cast(y_pred, tf.float32)\n\n        y_true_f = tf.keras.layers.Flatten()(y_true)\n        y_pred_f = tf.keras.layers.Flatten()(y_pred)\n        intersection = tf.reduce_sum(y_true_f * y_pred_f)\n        dice = (2. * intersection + smooth) / (tf.reduce_sum(y_true_f) + tf.reduce_sum(y_pred_f) + smooth)\n        return dice\n\n    def dice_coef_loss(self, y_true, y_pred):\n        return -self.dice_coef(y_true, y_pred)\n\n    def iou(self, y_true, y_pred):\n        y_true = tf.cast(y_true, tf.float32)\n        y_pred = tf.cast(y_pred, tf.float32)\n\n        intersection = tf.reduce_sum(tf.multiply(y_true, y_pred))\n        union = tf.reduce_sum(y_true) + tf.reduce_sum(y_pred) - intersection\n        iou = (intersection + 1e-15) / (union + 1e-15)\n        return iou\n\n    def CompileandSummarize(self, model_):\n        model_.compile(optimizer=tf.keras.optimizers.Adam(), loss=self.dice_coef_loss, metrics=[self.iou])\n        model_.summary()\n        return model_\n\n\n","metadata":{"execution":{"iopub.status.busy":"2023-05-10T23:34:42.917608Z","iopub.execute_input":"2023-05-10T23:34:42.918136Z","iopub.status.idle":"2023-05-10T23:34:42.959853Z","shell.execute_reply.started":"2023-05-10T23:34:42.918102Z","shell.execute_reply":"2023-05-10T23:34:42.958083Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"'''Defining callbacks to calculate training time '''\n\nfrom timeit import default_timer as timer\n\nclass TimingCallback(keras.callbacks.Callback):\n    def __init__(self, logs={}):\n        self.logs=[]\n    def on_epoch_begin(self, epoch, logs={}):\n        self.starttime = timer()\n    def on_epoch_end(self, epoch, logs={}):\n        self.logs.append(timer()-self.starttime)\n","metadata":{"execution":{"iopub.status.busy":"2023-05-10T23:21:58.646741Z","iopub.execute_input":"2023-05-10T23:21:58.647365Z","iopub.status.idle":"2023-05-10T23:21:58.653517Z","shell.execute_reply.started":"2023-05-10T23:21:58.647336Z","shell.execute_reply":"2023-05-10T23:21:58.652321Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"# Now lets focus on preparing the data\n\nwith ZipFile(\"../input/data-science-bowl-2018/stage1_train.zip\",\"r\") as zip_ref:\n    zip_ref.extractall(\"./stage1_train\")\n    \nwith ZipFile(\"../input/data-science-bowl-2018/stage1_test.zip\",\"r\") as zip_ref:\n    zip_ref.extractall(\"./stage1_test\")    ","metadata":{"execution":{"iopub.status.busy":"2023-05-10T23:21:59.190658Z","iopub.execute_input":"2023-05-10T23:21:59.191613Z","iopub.status.idle":"2023-05-10T23:22:04.991288Z","shell.execute_reply.started":"2023-05-10T23:21:59.191571Z","shell.execute_reply":"2023-05-10T23:22:04.990250Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"seed = 42\nnp.random.seed = seed\n\nIMG_WIDTH = 96\nIMG_HEIGHT = 96\nIMG_CHANNELS = 3\n\nTRAIN_PATH = './stage1_train/'\nTEST_PATH = './stage1_test/'","metadata":{"execution":{"iopub.status.busy":"2023-05-10T23:22:04.993233Z","iopub.execute_input":"2023-05-10T23:22:04.993586Z","iopub.status.idle":"2023-05-10T23:22:04.999678Z","shell.execute_reply.started":"2023-05-10T23:22:04.993554Z","shell.execute_reply":"2023-05-10T23:22:04.998765Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"train_ids = next(os.walk(TRAIN_PATH))[1]\ntest_ids = next(os.walk(TEST_PATH))[1]\n","metadata":{"execution":{"iopub.status.busy":"2023-05-10T23:22:05.001089Z","iopub.execute_input":"2023-05-10T23:22:05.001678Z","iopub.status.idle":"2023-05-10T23:22:05.074965Z","shell.execute_reply.started":"2023-05-10T23:22:05.001646Z","shell.execute_reply":"2023-05-10T23:22:05.074128Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"X_train = np.zeros((len(train_ids), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.uint8)\nY_train = np.zeros((len(train_ids), IMG_HEIGHT, IMG_WIDTH, 1), dtype=np.bool)\n\nprint('Resizing training images and masks')\nfor n, file_name in tqdm(enumerate(train_ids)):   \n    path = TRAIN_PATH + file_name\n    img = imread(path + '/images/' + file_name + '.png')[:,:,:IMG_CHANNELS]  \n    img = resize(img, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)\n    X_train[n] = img  #Fill empty X_train with values from img\n    mask = np.zeros((IMG_HEIGHT, IMG_WIDTH, 1), dtype=np.bool)\n    for mask_file in next(os.walk(path + '/masks/'))[2]:\n        mask_ = imread(path + '/masks/' + mask_file)\n        mask_ = np.expand_dims(resize(mask_, (IMG_HEIGHT, IMG_WIDTH), mode='constant',  \n                                      preserve_range=True), axis=-1)\n        mask = np.maximum(mask, mask_)  \n            \n    Y_train[n] = mask","metadata":{"execution":{"iopub.status.busy":"2023-05-10T23:22:05.078369Z","iopub.execute_input":"2023-05-10T23:22:05.079175Z","iopub.status.idle":"2023-05-10T23:26:57.821152Z","shell.execute_reply.started":"2023-05-10T23:22:05.079140Z","shell.execute_reply":"2023-05-10T23:26:57.819181Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_31/2570245034.py:2: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\nDeprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n  Y_train = np.zeros((len(train_ids), IMG_HEIGHT, IMG_WIDTH, 1), dtype=np.bool)\n","output_type":"stream"},{"name":"stdout","text":"Resizing training images and masks\n","output_type":"stream"},{"name":"stderr","text":"0it [00:00, ?it/s]/tmp/ipykernel_31/2570245034.py:10: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\nDeprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n  mask = np.zeros((IMG_HEIGHT, IMG_WIDTH, 1), dtype=np.bool)\n670it [04:52,  2.29it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"# test images\nX_test = np.zeros((len(test_ids), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.uint8)\nsizes_test = []\nprint('Resizing test images') \nfor n, id_ in tqdm(enumerate(test_ids), total=len(test_ids)):\n    path = TEST_PATH + id_\n    img = imread(path + '/images/' + id_ + '.png')[:,:,:IMG_CHANNELS]\n    sizes_test.append([img.shape[0], img.shape[1]])\n    img = resize(img, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)\n    X_test[n] = img\n","metadata":{"execution":{"iopub.status.busy":"2023-05-10T23:27:19.290464Z","iopub.execute_input":"2023-05-10T23:27:19.290854Z","iopub.status.idle":"2023-05-10T23:27:20.735923Z","shell.execute_reply.started":"2023-05-10T23:27:19.290823Z","shell.execute_reply":"2023-05-10T23:27:20.734821Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"Resizing test images\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 65/65 [00:01<00:00, 45.42it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"class GCU(tf.keras.layers.Layer):\n    def __init__(self):\n        super(GCU, self).__init__()\n    \n    def call(self, x):\n        return tf.cast(tf.math.multiply(x , tf.math.cos(x))/tf.reduce_sum(x), tf.float32)","metadata":{"execution":{"iopub.status.busy":"2023-05-10T23:27:22.778263Z","iopub.execute_input":"2023-05-10T23:27:22.778626Z","iopub.status.idle":"2023-05-10T23:27:22.784572Z","shell.execute_reply.started":"2023-05-10T23:27:22.778595Z","shell.execute_reply":"2023-05-10T23:27:22.783651Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"\ntraining_inferences = {}\ncb = TimingCallback()\n\nUNet_1 = UNet((96, 96, 3), activation_= \"relu\")\nmodel1 = UNet_1.buildModel()\nUNet_1.CompileandSummarize(model1)\nresults1 = model1.fit(x = X_train, y = Y_train, batch_size = 8, epochs=100, callbacks = [cb])\n\ntraining_inferences['ReLU'] = sum(cb.logs)\n","metadata":{"execution":{"iopub.status.busy":"2023-05-10T23:34:47.333045Z","iopub.execute_input":"2023-05-10T23:34:47.333395Z","iopub.status.idle":"2023-05-10T23:37:12.866132Z","shell.execute_reply.started":"2023-05-10T23:34:47.333367Z","shell.execute_reply":"2023-05-10T23:37:12.865099Z"},"trusted":true},"execution_count":34,"outputs":[{"name":"stdout","text":"Model: \"model_1\"\n__________________________________________________________________________________________________\n Layer (type)                   Output Shape         Param #     Connected to                     \n==================================================================================================\n input_2 (InputLayer)           [(None, 96, 96, 3)]  0           []                               \n                                                                                                  \n conv2d_133 (Conv2D)            (None, 96, 96, 16)   448         ['input_2[0][0]']                \n                                                                                                  \n conv2d_134 (Conv2D)            (None, 96, 96, 16)   2320        ['conv2d_133[0][0]']             \n                                                                                                  \n max_pooling2d_28 (MaxPooling2D  (None, 48, 48, 16)  0           ['conv2d_134[0][0]']             \n )                                                                                                \n                                                                                                  \n conv2d_135 (Conv2D)            (None, 48, 48, 32)   4640        ['max_pooling2d_28[0][0]']       \n                                                                                                  \n conv2d_136 (Conv2D)            (None, 48, 48, 32)   9248        ['conv2d_135[0][0]']             \n                                                                                                  \n max_pooling2d_29 (MaxPooling2D  (None, 24, 24, 32)  0           ['conv2d_136[0][0]']             \n )                                                                                                \n                                                                                                  \n conv2d_137 (Conv2D)            (None, 24, 24, 64)   18496       ['max_pooling2d_29[0][0]']       \n                                                                                                  \n conv2d_138 (Conv2D)            (None, 24, 24, 64)   36928       ['conv2d_137[0][0]']             \n                                                                                                  \n max_pooling2d_30 (MaxPooling2D  (None, 12, 12, 64)  0           ['conv2d_138[0][0]']             \n )                                                                                                \n                                                                                                  \n conv2d_139 (Conv2D)            (None, 12, 12, 128)  73856       ['max_pooling2d_30[0][0]']       \n                                                                                                  \n conv2d_140 (Conv2D)            (None, 12, 12, 128)  147584      ['conv2d_139[0][0]']             \n                                                                                                  \n max_pooling2d_31 (MaxPooling2D  (None, 6, 6, 128)   0           ['conv2d_140[0][0]']             \n )                                                                                                \n                                                                                                  \n conv2d_141 (Conv2D)            (None, 6, 6, 256)    295168      ['max_pooling2d_31[0][0]']       \n                                                                                                  \n conv2d_142 (Conv2D)            (None, 6, 6, 256)    590080      ['conv2d_141[0][0]']             \n                                                                                                  \n conv2d_transpose_34 (Conv2DTra  (None, 12, 12, 128)  131200     ['conv2d_142[0][0]']             \n nspose)                                                                                          \n                                                                                                  \n concatenate_28 (Concatenate)   (None, 12, 12, 256)  0           ['conv2d_transpose_34[0][0]',    \n                                                                  'conv2d_140[0][0]']             \n                                                                                                  \n conv2d_143 (Conv2D)            (None, 12, 12, 128)  295040      ['concatenate_28[0][0]']         \n                                                                                                  \n conv2d_144 (Conv2D)            (None, 12, 12, 128)  147584      ['conv2d_143[0][0]']             \n                                                                                                  \n conv2d_transpose_35 (Conv2DTra  (None, 24, 24, 64)  32832       ['conv2d_144[0][0]']             \n nspose)                                                                                          \n                                                                                                  \n concatenate_29 (Concatenate)   (None, 24, 24, 128)  0           ['conv2d_transpose_35[0][0]',    \n                                                                  'conv2d_138[0][0]']             \n                                                                                                  \n conv2d_145 (Conv2D)            (None, 24, 24, 64)   73792       ['concatenate_29[0][0]']         \n                                                                                                  \n conv2d_146 (Conv2D)            (None, 24, 24, 64)   36928       ['conv2d_145[0][0]']             \n                                                                                                  \n conv2d_transpose_37 (Conv2DTra  (None, 48, 48, 32)  8224        ['conv2d_146[0][0]']             \n nspose)                                                                                          \n                                                                                                  \n concatenate_30 (Concatenate)   (None, 48, 48, 64)   0           ['conv2d_transpose_37[0][0]',    \n                                                                  'conv2d_136[0][0]']             \n                                                                                                  \n conv2d_147 (Conv2D)            (None, 48, 48, 32)   18464       ['concatenate_30[0][0]']         \n                                                                                                  \n conv2d_148 (Conv2D)            (None, 48, 48, 32)   9248        ['conv2d_147[0][0]']             \n                                                                                                  \n conv2d_transpose_38 (Conv2DTra  (None, 96, 96, 16)  2064        ['conv2d_148[0][0]']             \n nspose)                                                                                          \n                                                                                                  \n concatenate_31 (Concatenate)   (None, 96, 96, 32)   0           ['conv2d_transpose_38[0][0]',    \n                                                                  'conv2d_134[0][0]']             \n                                                                                                  \n conv2d_149 (Conv2D)            (None, 96, 96, 16)   4624        ['concatenate_31[0][0]']         \n                                                                                                  \n conv2d_150 (Conv2D)            (None, 96, 96, 16)   2320        ['conv2d_149[0][0]']             \n                                                                                                  \n conv2d_151 (Conv2D)            (None, 96, 96, 1)    17          ['conv2d_150[0][0]']             \n                                                                                                  \n==================================================================================================\nTotal params: 1,941,105\nTrainable params: 1,941,105\nNon-trainable params: 0\n__________________________________________________________________________________________________\nEpoch 1/100\n84/84 [==============================] - 8s 16ms/step - loss: -0.7197 - iou: 0.5880\nEpoch 2/100\n84/84 [==============================] - 1s 15ms/step - loss: -0.9058 - iou: 0.8296\nEpoch 3/100\n84/84 [==============================] - 2s 18ms/step - loss: -0.9213 - iou: 0.8547\nEpoch 4/100\n84/84 [==============================] - 1s 16ms/step - loss: -0.9041 - iou: 0.8277\nEpoch 5/100\n84/84 [==============================] - 1s 15ms/step - loss: -0.9251 - iou: 0.8612\nEpoch 6/100\n84/84 [==============================] - 1s 16ms/step - loss: -0.9309 - iou: 0.8713\nEpoch 7/100\n84/84 [==============================] - 1s 16ms/step - loss: -0.9317 - iou: 0.8728\nEpoch 8/100\n84/84 [==============================] - 1s 15ms/step - loss: -0.9313 - iou: 0.8723\nEpoch 9/100\n84/84 [==============================] - 1s 15ms/step - loss: -0.9310 - iou: 0.8719\nEpoch 10/100\n84/84 [==============================] - 1s 15ms/step - loss: -0.9333 - iou: 0.8754\nEpoch 11/100\n84/84 [==============================] - 1s 14ms/step - loss: -0.9369 - iou: 0.8819\nEpoch 12/100\n84/84 [==============================] - 1s 14ms/step - loss: -0.9361 - iou: 0.8800\nEpoch 13/100\n84/84 [==============================] - 1s 14ms/step - loss: -0.9378 - iou: 0.8832\nEpoch 14/100\n84/84 [==============================] - 1s 16ms/step - loss: -0.9369 - iou: 0.8816\nEpoch 15/100\n84/84 [==============================] - 1s 16ms/step - loss: -0.9375 - iou: 0.8829\nEpoch 16/100\n84/84 [==============================] - 1s 15ms/step - loss: -0.9394 - iou: 0.8861\nEpoch 17/100\n84/84 [==============================] - 1s 15ms/step - loss: -0.9399 - iou: 0.8870\nEpoch 18/100\n84/84 [==============================] - 1s 15ms/step - loss: -0.9384 - iou: 0.8845\nEpoch 19/100\n84/84 [==============================] - 1s 15ms/step - loss: -0.9413 - iou: 0.8897\nEpoch 20/100\n84/84 [==============================] - 1s 15ms/step - loss: -0.9402 - iou: 0.8875\nEpoch 21/100\n84/84 [==============================] - 1s 15ms/step - loss: -0.9418 - iou: 0.8906\nEpoch 22/100\n84/84 [==============================] - 1s 15ms/step - loss: -0.9423 - iou: 0.8911\nEpoch 23/100\n84/84 [==============================] - 1s 15ms/step - loss: -0.9410 - iou: 0.8892\nEpoch 24/100\n84/84 [==============================] - 1s 16ms/step - loss: -0.9418 - iou: 0.8906\nEpoch 25/100\n84/84 [==============================] - 1s 14ms/step - loss: -0.9451 - iou: 0.8963\nEpoch 26/100\n84/84 [==============================] - 1s 15ms/step - loss: -0.9457 - iou: 0.8975\nEpoch 27/100\n84/84 [==============================] - 1s 14ms/step - loss: -0.9456 - iou: 0.8973\nEpoch 28/100\n84/84 [==============================] - 2s 19ms/step - loss: -0.9461 - iou: 0.8981\nEpoch 29/100\n84/84 [==============================] - 1s 16ms/step - loss: -0.9392 - iou: 0.8859\nEpoch 30/100\n84/84 [==============================] - 1s 14ms/step - loss: -0.9448 - iou: 0.8961\nEpoch 31/100\n84/84 [==============================] - 1s 16ms/step - loss: -0.9425 - iou: 0.8920\nEpoch 32/100\n84/84 [==============================] - 1s 16ms/step - loss: -0.9448 - iou: 0.8956\nEpoch 33/100\n84/84 [==============================] - 1s 14ms/step - loss: -0.9461 - iou: 0.8983\nEpoch 34/100\n84/84 [==============================] - 1s 14ms/step - loss: -0.9490 - iou: 0.9031\nEpoch 35/100\n84/84 [==============================] - 1s 15ms/step - loss: -0.9464 - iou: 0.8987\nEpoch 36/100\n84/84 [==============================] - 1s 14ms/step - loss: -0.9470 - iou: 0.8996\nEpoch 37/100\n84/84 [==============================] - 1s 15ms/step - loss: -0.9468 - iou: 0.8994\nEpoch 38/100\n84/84 [==============================] - 1s 15ms/step - loss: -0.9485 - iou: 0.9025\nEpoch 39/100\n84/84 [==============================] - 1s 15ms/step - loss: -0.9503 - iou: 0.9056\nEpoch 40/100\n84/84 [==============================] - 1s 15ms/step - loss: -0.9477 - iou: 0.9013\nEpoch 41/100\n84/84 [==============================] - 1s 16ms/step - loss: -0.9498 - iou: 0.9046\nEpoch 42/100\n84/84 [==============================] - 1s 14ms/step - loss: -0.9478 - iou: 0.9018\nEpoch 43/100\n84/84 [==============================] - 1s 15ms/step - loss: -0.9508 - iou: 0.9063\nEpoch 44/100\n84/84 [==============================] - 1s 15ms/step - loss: -0.9503 - iou: 0.9055\nEpoch 45/100\n84/84 [==============================] - 1s 15ms/step - loss: -0.9501 - iou: 0.9052\nEpoch 46/100\n84/84 [==============================] - 1s 15ms/step - loss: -0.9498 - iou: 0.9047\nEpoch 47/100\n84/84 [==============================] - 1s 15ms/step - loss: -0.9526 - iou: 0.9096\nEpoch 48/100\n84/84 [==============================] - 1s 15ms/step - loss: -0.9519 - iou: 0.9089\nEpoch 49/100\n84/84 [==============================] - 1s 15ms/step - loss: -0.9533 - iou: 0.9111\nEpoch 50/100\n84/84 [==============================] - 1s 16ms/step - loss: -0.9552 - iou: 0.9145\nEpoch 51/100\n84/84 [==============================] - 1s 15ms/step - loss: -0.9539 - iou: 0.9121\nEpoch 52/100\n84/84 [==============================] - 1s 15ms/step - loss: -0.9540 - iou: 0.9121\nEpoch 53/100\n84/84 [==============================] - 2s 20ms/step - loss: -0.9544 - iou: 0.9128\nEpoch 54/100\n84/84 [==============================] - 1s 16ms/step - loss: -0.9528 - iou: 0.9099\nEpoch 55/100\n84/84 [==============================] - 1s 15ms/step - loss: -0.9534 - iou: 0.9111\nEpoch 56/100\n84/84 [==============================] - 1s 15ms/step - loss: -0.9529 - iou: 0.9103\nEpoch 57/100\n84/84 [==============================] - 1s 15ms/step - loss: -0.9553 - iou: 0.9144\nEpoch 58/100\n84/84 [==============================] - 1s 16ms/step - loss: -0.9559 - iou: 0.9156\nEpoch 59/100\n84/84 [==============================] - 1s 15ms/step - loss: -0.9561 - iou: 0.9159\nEpoch 60/100\n84/84 [==============================] - 1s 14ms/step - loss: -0.9552 - iou: 0.9146\nEpoch 61/100\n84/84 [==============================] - 1s 14ms/step - loss: -0.9564 - iou: 0.9165\nEpoch 62/100\n84/84 [==============================] - 1s 15ms/step - loss: -0.9555 - iou: 0.9151\nEpoch 63/100\n84/84 [==============================] - 1s 15ms/step - loss: -0.9573 - iou: 0.9182\nEpoch 64/100\n84/84 [==============================] - 1s 15ms/step - loss: -0.9560 - iou: 0.9161\nEpoch 65/100\n84/84 [==============================] - 1s 15ms/step - loss: -0.9573 - iou: 0.9181\nEpoch 66/100\n84/84 [==============================] - 1s 14ms/step - loss: -0.9571 - iou: 0.9178\nEpoch 67/100\n84/84 [==============================] - 1s 16ms/step - loss: -0.9590 - iou: 0.9212\nEpoch 68/100\n84/84 [==============================] - 1s 14ms/step - loss: -0.9571 - iou: 0.9179\nEpoch 69/100\n84/84 [==============================] - 1s 15ms/step - loss: -0.9584 - iou: 0.9201\nEpoch 70/100\n84/84 [==============================] - 1s 15ms/step - loss: -0.9581 - iou: 0.9196\nEpoch 71/100\n84/84 [==============================] - 1s 15ms/step - loss: -0.9587 - iou: 0.9207\nEpoch 72/100\n84/84 [==============================] - 1s 14ms/step - loss: -0.9586 - iou: 0.9205\nEpoch 73/100\n84/84 [==============================] - 1s 14ms/step - loss: -0.9583 - iou: 0.9201\nEpoch 74/100\n84/84 [==============================] - 1s 14ms/step - loss: -0.9565 - iou: 0.9168\nEpoch 75/100\n84/84 [==============================] - 1s 15ms/step - loss: -0.9577 - iou: 0.9190\nEpoch 76/100\n84/84 [==============================] - 1s 15ms/step - loss: -0.9589 - iou: 0.9211\nEpoch 77/100\n84/84 [==============================] - 1s 16ms/step - loss: -0.9584 - iou: 0.9202\nEpoch 78/100\n84/84 [==============================] - 2s 18ms/step - loss: -0.9572 - iou: 0.9182\nEpoch 79/100\n84/84 [==============================] - 1s 16ms/step - loss: -0.9582 - iou: 0.9198\nEpoch 80/100\n84/84 [==============================] - 1s 15ms/step - loss: -0.9593 - iou: 0.9219\nEpoch 81/100\n84/84 [==============================] - 1s 14ms/step - loss: -0.9595 - iou: 0.9222\nEpoch 82/100\n84/84 [==============================] - 1s 15ms/step - loss: -0.9594 - iou: 0.9221\nEpoch 83/100\n84/84 [==============================] - 1s 15ms/step - loss: -0.9592 - iou: 0.9215\nEpoch 84/100\n84/84 [==============================] - 1s 16ms/step - loss: -0.9581 - iou: 0.9196\nEpoch 85/100\n84/84 [==============================] - 1s 15ms/step - loss: -0.9584 - iou: 0.9203\nEpoch 86/100\n84/84 [==============================] - 1s 14ms/step - loss: -0.9600 - iou: 0.9232\nEpoch 87/100\n84/84 [==============================] - 1s 15ms/step - loss: -0.9597 - iou: 0.9226\nEpoch 88/100\n84/84 [==============================] - 1s 15ms/step - loss: -0.9601 - iou: 0.9233\nEpoch 89/100\n84/84 [==============================] - 1s 15ms/step - loss: -0.9602 - iou: 0.9236\nEpoch 90/100\n84/84 [==============================] - 1s 15ms/step - loss: -0.9604 - iou: 0.9238\nEpoch 91/100\n84/84 [==============================] - 1s 15ms/step - loss: -0.9603 - iou: 0.9236\nEpoch 92/100\n84/84 [==============================] - 1s 15ms/step - loss: -0.9611 - iou: 0.9252\nEpoch 93/100\n84/84 [==============================] - 1s 16ms/step - loss: -0.9608 - iou: 0.9247\nEpoch 94/100\n84/84 [==============================] - 1s 15ms/step - loss: -0.9593 - iou: 0.9220\nEpoch 95/100\n84/84 [==============================] - 1s 15ms/step - loss: -0.9585 - iou: 0.9203\nEpoch 96/100\n84/84 [==============================] - 1s 14ms/step - loss: -0.9587 - iou: 0.9207\nEpoch 97/100\n84/84 [==============================] - 1s 14ms/step - loss: -0.9581 - iou: 0.9198\nEpoch 98/100\n84/84 [==============================] - 1s 15ms/step - loss: -0.9590 - iou: 0.9213\nEpoch 99/100\n84/84 [==============================] - 1s 15ms/step - loss: -0.9599 - iou: 0.9231\nEpoch 100/100\n84/84 [==============================] - 1s 15ms/step - loss: -0.9594 - iou: 0.9222\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}